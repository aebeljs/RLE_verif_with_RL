[main]
; number of steps for which the experiment is run
num_steps = 10

; number of functional events tracked
num_events = 5

; weightage of each event for reward computation
reward_function = [0, 1, 0, 1, 1]

; set log_step as 0 for logging just aggregated results and 1 for logging details in each step
log_step = 0

; set mode as 0 to generate the random baseline without RL and 1 for using RL
mode = 1

[cocotb]
; length of fsm_states list will be the number of continuous action knobs (refer to the docs for more details)
fsm_states = ['.']

; provide the discrete parameter keys here
discrete_params = ['count_width', 'fmap_len']

; provide the list of valid discrete values for each parameter in this section
[discrete]
count_width = [1, 2, 3, 4, 5, 6, 7, 8]
fmap_len = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]

; refer to the stable_baselines3 SAC documentation for the hyperparameters in this section
[RL]
learning_starts = 100
learning_rate = 0.0003
train_freq = (1, 'episode')
