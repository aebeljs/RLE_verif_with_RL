[main]
; number of steps for which the experiment is run
num_steps = 1000

; number of functional events tracked
num_events = 10

; weightage of each event for reward computation
reward_function = [0,0,0,0,2,0,0,0,0,0]

; set log_step as 0 for logging just aggregated results and 1 for logging details in each step
log_step = 0

; set mode as 0 to generate the random baseline without RL and 1 for using RL
mode = 0

[cocotb]
; length of fsm_states list will be the number of continuous action knobs (refer to the docs for more details)
fsm_states = []

; provide the discrete parameter keys here
discrete_params = ['master_wr_addr_0', 'master_wr_addr_1']

; provide the list of valid discrete values for each parameter in this section
[discrete]
master_wr_addr_0 = [4096, 8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960]
master_wr_addr_1 = [4096, 8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960]

; refer to the stable_baselines3 SAC documentation for the hyperparameters in this section
[RL]
learning_starts = 300
learning_rate = 0.0003
train_freq = (1, 'episode')
